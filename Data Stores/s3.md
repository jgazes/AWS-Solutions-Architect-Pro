# Simple Storage Service #
[Amazon S3 Update â€“ Strong Read-After-Write Consistency](https://aws.amazon.com/blogs/aws/amazon-s3-update-strong-read-after-write-consistency/)
- One of the first AWS services introduced back in 2006
- s3 is an object store
- Used in other AWS services - directly and behind-the-scenes
- Max obj size is 5TB; largest object in a single PUT is 5GB
- Recommended to use multi-part uploads if larger than 100MB
- s3 looks like a file path (s3://bucket/josh/text.txt) but its actually a key, like in a database that uniquely identifies a record

## S3 Security ##
- Resource based (Object ACL, Bucket Policy)
- User-based (IAM policies)
- Optional MFA before delete

## S3 Data Protection ##
Versioning:
- New version with each write
- Enables "roll-back" and "un-delete" capabilities
- Old versions count as billable size until they are permanently deleted.
- Integrated with Lifecycle Management

Optionally require MFA:
- Safeguard against accidental deletion of an object
- Change the versioning state of your bucket

Cross-Region Replication:
- Security
- Compliance
- Latency 

## S3 Storage Classes ##
- Standard: Frequently accessed data
- Standar-IA: Long-lived, infrequently accessed data
- One Zone-IA: Long-lived, infrequently accessed, non-critical data (one availability zone)
- Reduced redundancy: Frequently accessed, non-critical data
- Intelligent-Tiering: Long-lived data with changing or unknown access patterns
*how long does data sit in intelligent tier before moving into another storage class?*
*Are there put charges associated with data moving from intelligent tier into other storage classes?*

- Glacier: Long-term data archiving retrieval times from mins to hrs
- Glacier Instant Retrieval- Fastest archive storage
- Glacier Flexible Retrieval- Was formerly known as s3 Glacier
- Glacier Deep Archive: Long-term data archiving retrieval 12 hrs

## S3 Lifecycle Management ##
- Optimize storage costs
- Adhere to data retention policies
- Keep S3 volumes well-maintained
- Seperate from S3 Intelligent tiering archiving

## S3 Analytics ##
- Data Lake Concept
- Athena, Redshift Spectrum, QuickSight
- IOT Streaming Data Repository
- Kinesis Firehose
- Machine Learning and AI Storage
- Rekognition, Lex, MXNet
- Storage Class Analysis
- S3 Management Analytics

## S3 Encryption at Rest ##
- SSE-S3: S3's existing ecryption key for AES-256
- SSE-C: Upload your own AES encryption key which s3 will use when it writes the objects
- SSE-KMS: Use a key generated and managed by AWS KMS
- Client-Side: Encrypt objects using your own local encryption process before uploading (PGP,GPG)

## S3 Tricks ##
- Transfer Acceleration: Speed up data uploads using CloudFront in reverse
- Requester Pays: The requester rather than bucket owner pays for the data transfer
- Tags: Assign tags on objects for use in costing billing security
- Events: Trigger notifications to SNS, SQS or Lambda when certain events happen in your bucket
- Static Web Hosting: Simple and massively scalable static webiste hosting
- BitTorrent: Use the BitTorrent protocol to retrieve any publicly available object by automatically generating a .torrent file

